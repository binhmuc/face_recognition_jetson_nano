{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "fa = FaceAligner(predictor, desiredFaceWidth=196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImageAlgin(imgPath):\n",
    "    image = cv2.imread(imgPath)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray, 1)\n",
    "    if len(faces) > 0:\n",
    "        rect = faces[0]\n",
    "        faceAligned = fa.align(image, gray, rect)\n",
    "        rects = detector(faceAligned, 1)\n",
    "        if len(rects) > 0:\n",
    "            rect = detector(faceAligned, 1)[0]\n",
    "            (x, y, w, h) = rect_to_bb(rect)\n",
    "            return cv2.resize(faceAligned[y:y + h, x:x + w], (96,96))\n",
    "        else :\n",
    "            return False\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "from utils import LRN2D\n",
    "import utils\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed to create session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e0b44e37eb33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyInput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bn1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/layers/normalization.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    181\u001b[0m         normed_training, mean, variance = K.normalize_batch_in_training(\n\u001b[1;32m    182\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             epsilon=self.epsilon)\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'cntk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mnormalize_batch_in_training\u001b[0;34m(x, gamma, beta, reduction_axes, epsilon)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \"\"\"\n\u001b[1;32m   1835\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1836\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_has_nchw_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction_axes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1837\u001b[0m             return _broadcast_normalize_batch_in_training(x, gamma, beta,\n\u001b[1;32m   1838\u001b[0m                                                           \u001b[0mreduction_axes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_has_nchw_support\u001b[0;34m()\u001b[0m\n\u001b[1;32m    288\u001b[0m     \"\"\"\n\u001b[1;32m    289\u001b[0m     \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_current_explicit_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CPU'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m     \u001b[0mgpus_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mexplicitly_on_cpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpus_available\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_get_available_gpus\u001b[0;34m()\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_LOCAL_DEVICES\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'GPU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m                 config = tf.ConfigProto(intra_op_parallelism_threads=num_thread,\n\u001b[1;32m    183\u001b[0m                                         allow_soft_placement=True)\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0m_SESSION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SESSION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m   1558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m     \"\"\"\n\u001b[0;32m-> 1560\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1561\u001b[0m     \u001b[0;31m# NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_graph_context_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, target, graph, config)\u001b[0m\n\u001b[1;32m    631\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed to create session."
     ]
    }
   ],
   "source": [
    "myInput = Input(shape=(96, 96, 3))\n",
    "\n",
    "x = ZeroPadding2D(padding=(3, 3), input_shape=(96, 96, 3))(myInput)\n",
    "x = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn1')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "x = Lambda(LRN2D, name='lrn_1')(x)\n",
    "x = Conv2D(64, (1, 1), name='conv2')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn2')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = Conv2D(192, (3, 3), name='conv3')(x)\n",
    "x = BatchNormalization(axis=3, epsilon=0.00001, name='bn3')(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Lambda(LRN2D, name='lrn_2')(x)\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "# Inception3a\n",
    "inception_3a_3x3 = Conv2D(96, (1, 1), name='inception_3a_3x3_conv1')(x)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn1')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "inception_3a_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3a_3x3)\n",
    "inception_3a_3x3 = Conv2D(128, (3, 3), name='inception_3a_3x3_conv2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_3x3_bn2')(inception_3a_3x3)\n",
    "inception_3a_3x3 = Activation('relu')(inception_3a_3x3)\n",
    "\n",
    "inception_3a_5x5 = Conv2D(16, (1, 1), name='inception_3a_5x5_conv1')(x)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn1')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "inception_3a_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3a_5x5)\n",
    "inception_3a_5x5 = Conv2D(32, (5, 5), name='inception_3a_5x5_conv2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_5x5_bn2')(inception_3a_5x5)\n",
    "inception_3a_5x5 = Activation('relu')(inception_3a_5x5)\n",
    "\n",
    "inception_3a_pool = MaxPooling2D(pool_size=3, strides=2)(x)\n",
    "inception_3a_pool = Conv2D(32, (1, 1), name='inception_3a_pool_conv')(inception_3a_pool)\n",
    "inception_3a_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_pool_bn')(inception_3a_pool)\n",
    "inception_3a_pool = Activation('relu')(inception_3a_pool)\n",
    "inception_3a_pool = ZeroPadding2D(padding=((3, 4), (3, 4)))(inception_3a_pool)\n",
    "\n",
    "inception_3a_1x1 = Conv2D(64, (1, 1), name='inception_3a_1x1_conv')(x)\n",
    "inception_3a_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3a_1x1_bn')(inception_3a_1x1)\n",
    "inception_3a_1x1 = Activation('relu')(inception_3a_1x1)\n",
    "\n",
    "inception_3a = concatenate([inception_3a_3x3, inception_3a_5x5, inception_3a_pool, inception_3a_1x1], axis=3)\n",
    "\n",
    "# Inception3b\n",
    "inception_3b_3x3 = Conv2D(96, (1, 1), name='inception_3b_3x3_conv1')(inception_3a)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn1')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "inception_3b_3x3 = ZeroPadding2D(padding=(1, 1))(inception_3b_3x3)\n",
    "inception_3b_3x3 = Conv2D(128, (3, 3), name='inception_3b_3x3_conv2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_3x3_bn2')(inception_3b_3x3)\n",
    "inception_3b_3x3 = Activation('relu')(inception_3b_3x3)\n",
    "\n",
    "inception_3b_5x5 = Conv2D(32, (1, 1), name='inception_3b_5x5_conv1')(inception_3a)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn1')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "inception_3b_5x5 = ZeroPadding2D(padding=(2, 2))(inception_3b_5x5)\n",
    "inception_3b_5x5 = Conv2D(64, (5, 5), name='inception_3b_5x5_conv2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_5x5_bn2')(inception_3b_5x5)\n",
    "inception_3b_5x5 = Activation('relu')(inception_3b_5x5)\n",
    "\n",
    "inception_3b_pool = Lambda(lambda x: x**2, name='power2_3b')(inception_3a)\n",
    "inception_3b_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: x*9, name='mult9_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_3b')(inception_3b_pool)\n",
    "inception_3b_pool = Conv2D(64, (1, 1), name='inception_3b_pool_conv')(inception_3b_pool)\n",
    "inception_3b_pool = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_pool_bn')(inception_3b_pool)\n",
    "inception_3b_pool = Activation('relu')(inception_3b_pool)\n",
    "inception_3b_pool = ZeroPadding2D(padding=(4, 4))(inception_3b_pool)\n",
    "\n",
    "inception_3b_1x1 = Conv2D(64, (1, 1), name='inception_3b_1x1_conv')(inception_3a)\n",
    "inception_3b_1x1 = BatchNormalization(axis=3, epsilon=0.00001, name='inception_3b_1x1_bn')(inception_3b_1x1)\n",
    "inception_3b_1x1 = Activation('relu')(inception_3b_1x1)\n",
    "\n",
    "inception_3b = concatenate([inception_3b_3x3, inception_3b_5x5, inception_3b_pool, inception_3b_1x1], axis=3)\n",
    "\n",
    "# Inception3c\n",
    "inception_3c_3x3 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_3x3',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_3c_5x5 = utils.conv2d_bn(inception_3b,\n",
    "                                   layer='inception_3c_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_3c_pool = MaxPooling2D(pool_size=3, strides=2)(inception_3b)\n",
    "inception_3c_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_3c_pool)\n",
    "\n",
    "inception_3c = concatenate([inception_3c_3x3, inception_3c_5x5, inception_3c_pool], axis=3)\n",
    "\n",
    "#inception 4a\n",
    "inception_4a_3x3 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=192,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_4a_5x5 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_5x5',\n",
    "                                   cv1_out=32,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=64,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "\n",
    "inception_4a_pool = Lambda(lambda x: x**2, name='power2_4a')(inception_3c)\n",
    "inception_4a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: x*9, name='mult9_4a')(inception_4a_pool)\n",
    "inception_4a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_4a')(inception_4a_pool)\n",
    "inception_4a_pool = utils.conv2d_bn(inception_4a_pool,\n",
    "                                   layer='inception_4a_pool',\n",
    "                                   cv1_out=128,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(2, 2))\n",
    "inception_4a_1x1 = utils.conv2d_bn(inception_3c,\n",
    "                                   layer='inception_4a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_4a = concatenate([inception_4a_3x3, inception_4a_5x5, inception_4a_pool, inception_4a_1x1], axis=3)\n",
    "\n",
    "#inception4e\n",
    "inception_4e_3x3 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_3x3',\n",
    "                                   cv1_out=160,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=256,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(1, 1))\n",
    "inception_4e_5x5 = utils.conv2d_bn(inception_4a,\n",
    "                                   layer='inception_4e_5x5',\n",
    "                                   cv1_out=64,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=128,\n",
    "                                   cv2_filter=(5, 5),\n",
    "                                   cv2_strides=(2, 2),\n",
    "                                   padding=(2, 2))\n",
    "inception_4e_pool = MaxPooling2D(pool_size=3, strides=2)(inception_4a)\n",
    "inception_4e_pool = ZeroPadding2D(padding=((0, 1), (0, 1)))(inception_4e_pool)\n",
    "\n",
    "inception_4e = concatenate([inception_4e_3x3, inception_4e_5x5, inception_4e_pool], axis=3)\n",
    "\n",
    "#inception5a\n",
    "inception_5a_3x3 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "\n",
    "inception_5a_pool = Lambda(lambda x: x**2, name='power2_5a')(inception_4e)\n",
    "inception_5a_pool = AveragePooling2D(pool_size=(3, 3), strides=(3, 3))(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: x*9, name='mult9_5a')(inception_5a_pool)\n",
    "inception_5a_pool = Lambda(lambda x: K.sqrt(x), name='sqrt_5a')(inception_5a_pool)\n",
    "inception_5a_pool = utils.conv2d_bn(inception_5a_pool,\n",
    "                                   layer='inception_5a_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5a_1x1 = utils.conv2d_bn(inception_4e,\n",
    "                                   layer='inception_5a_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "\n",
    "inception_5a = concatenate([inception_5a_3x3, inception_5a_pool, inception_5a_1x1], axis=3)\n",
    "\n",
    "#inception_5b\n",
    "inception_5b_3x3 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_3x3',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1),\n",
    "                                   cv2_out=384,\n",
    "                                   cv2_filter=(3, 3),\n",
    "                                   cv2_strides=(1, 1),\n",
    "                                   padding=(1, 1))\n",
    "inception_5b_pool = MaxPooling2D(pool_size=3, strides=2)(inception_5a)\n",
    "inception_5b_pool = utils.conv2d_bn(inception_5b_pool,\n",
    "                                   layer='inception_5b_pool',\n",
    "                                   cv1_out=96,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b_pool = ZeroPadding2D(padding=(1, 1))(inception_5b_pool)\n",
    "\n",
    "inception_5b_1x1 = utils.conv2d_bn(inception_5a,\n",
    "                                   layer='inception_5b_1x1',\n",
    "                                   cv1_out=256,\n",
    "                                   cv1_filter=(1, 1))\n",
    "inception_5b = concatenate([inception_5b_3x3, inception_5b_pool, inception_5b_1x1], axis=3)\n",
    "\n",
    "av_pool = AveragePooling2D(pool_size=(3, 3), strides=(1, 1))(inception_5b)\n",
    "reshape_layer = Flatten()(av_pool)\n",
    "dense_layer = Dense(128, name='dense_layer')(reshape_layer)\n",
    "norm_layer = Lambda(lambda  x: K.l2_normalize(x, axis=1), name='norm_layer')(dense_layer)\n",
    "\n",
    "\n",
    "# Final Model\n",
    "model = Model(inputs=[myInput], outputs=norm_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:269: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# model = load_model('./model/nn4.small2.lrn.h5')\n",
    "from keras.utils import CustomObjectScope\n",
    "import tensorflow as tf\n",
    "with CustomObjectScope({'tf': tf}):\n",
    "    model = load_model('./model/nn4.small2.lrn.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get128keypoint(imgPath):\n",
    "    faceAligned = getImageAlgin(imgPath)\n",
    "    if faceAligned is not False:\n",
    "        img = faceAligned[...,::-1]\n",
    "        img = np.around(np.transpose(img, (0,1,2))/255.0, decimals=12)\n",
    "        x_train = np.array([img])\n",
    "        y1 = model.predict_on_batch(x_train)\n",
    "        return y1[0]\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9fb754afc54d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget128keypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./images/mm7.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-97f3d6fadbda>\u001b[0m in \u001b[0;36mget128keypoint\u001b[0;34m(imgPath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget128keypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfaceAligned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetImageAlgin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfaceAligned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaceAligned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-05b341c575e2>\u001b[0m in \u001b[0;36mgetImageAlgin\u001b[0;34m(imgPath)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetImageAlgin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/imgproc/src/color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "get128keypoint('./images/mm7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05377739"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = get128keypoint('./images/pp9.jpg')\n",
    "y2 = get128keypoint('./images/thin8.jpg')\n",
    "dist = np.sqrt(np.sum(np.square(np.subtract(y1[0], y2[0]))))\n",
    "dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Enouvo_company/BuiMinhPhong\n",
      "./Enouvo_company/DangHy\n",
      "./Enouvo_company/HoThiKhanhLy\n",
      "./Enouvo_company/JasonNguyen\n",
      "./Enouvo_company/MaiThiThuThuy\n",
      "./Enouvo_company/NguyenHuuTuongVi\n",
      "./Enouvo_company/NguyenLeBaoTram\n",
      "./Enouvo_company/NguyenLinhGiang\n",
      "./Enouvo_company/NguyenNhatNam\n",
      "./Enouvo_company/NguyenThiThanhPhuong\n",
      "./Enouvo_company/NguyenTranAnhPhuong\n",
      "./Enouvo_company/NguyenTriCong\n",
      "./Enouvo_company/NguyenXuanHung\n",
      "./Enouvo_company/PhamSiNguyen\n",
      "./Enouvo_company/PhamThiNgocAnh\n",
      "./Enouvo_company/TranHanhTrang\n",
      "./Enouvo_company/TranTHiMyLinh\n",
      "./Enouvo_company/TranThiThuHien\n",
      "./Enouvo_company/TruongThiYNhi\n",
      "./Enouvo_company/VoThiThanhTuyen\n"
     ]
    }
   ],
   "source": [
    "persons = glob.glob(\"./Enouvo_company/*\")\n",
    "index = -1\n",
    "dataTrain = []\n",
    "labelTrain = []\n",
    "\n",
    "dataTest = []\n",
    "labelTest = []\n",
    "for person in persons:\n",
    "    print(person)\n",
    "    index = index + 1\n",
    "    imagesTrain = glob.glob(person + \"/Train/*.*\")\n",
    "    for image in imagesTrain:\n",
    "        k = get128keypoint(image)\n",
    "        if k is not False:\n",
    "            dataTrain.append(k)\n",
    "            labelTrain.append(index)\n",
    "    imagesTest = glob.glob(person + \"/Test/*.*\")\n",
    "    for image in imagesTest:\n",
    "        dataTest.append(image)\n",
    "        labelTest.append(index)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n"
     ]
    }
   ],
   "source": [
    "print(labelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/train/mm/mm.jpg\n",
      "./images/train/mm/mm10.jpg\n",
      "./images/train/mm/mm11.jpg\n",
      "./images/train/mm/mm12.jpg\n",
      "./images/train/mm/mm2.jpg\n",
      "./images/train/mm/mm3.jpg\n",
      "./images/train/mm/mm5.jpg\n",
      "./images/train/mm/mm6.jpg\n",
      "./images/train/mm/mm7.jpg\n",
      "./images/train/mm/mm8.jpg\n",
      "./images/train/mm/mm9.jpg\n",
      "./images/train/pp/pp.jpg\n",
      "./images/train/pp/pp10.jpg\n",
      "./images/train/pp/pp2.jpg\n",
      "./images/train/pp/pp3.jpg\n",
      "./images/train/pp/pp4.jpg\n",
      "./images/train/pp/pp5.jpg\n",
      "./images/train/pp/pp6.jpg\n",
      "./images/train/pp/pp7.jpg\n",
      "./images/train/pp/pp8.jpg\n",
      "./images/train/quynh/quynh1.jpg\n",
      "./images/train/quynh/quynh2.jpg\n",
      "./images/train/quynh/quynh4.jpg\n",
      "./images/train/quynh/quynh5.jpg\n",
      "./images/train/quynh/quynh6.jpg\n",
      "./images/train/quynh/quynh7.jpg\n",
      "./images/train/quynh/quynh8.jpg\n",
      "./images/train/quynh/quynh9.jpg\n",
      "./images/train/thien/thien.jpg\n",
      "./images/train/thien/thien1.jpg\n",
      "./images/train/thien/thien2.jpg\n",
      "./images/train/thien/thien3.jpg\n",
      "./images/train/thien/thien4.jpg\n",
      "./images/train/thien/thien5.jpg\n",
      "./images/train/thien/thien6.jpg\n",
      "./images/train/thin/thin.jpg\n",
      "./images/train/thin/thin2.jpg\n",
      "./images/train/thin/thin3.jpg\n",
      "./images/train/thin/thin4.jpg\n",
      "./images/train/thin/thin5.jpg\n",
      "./images/train/thin/thin6.jpg\n",
      "./images/train/thin/thin7.jpg\n",
      "./images/train/xp/xp.jpg\n",
      "./images/train/xp/xp2.jpg\n",
      "./images/train/xp/xp3.jpg\n",
      "./images/train/xp/xp4.jpg\n",
      "./images/train/xp/xp6.jpg\n",
      "./images/train/xp/xp7.jpg\n",
      "./images/train/xp/xp8.jpg\n",
      "./images/train/xp/xp9.jpg\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "label = []\n",
    "listfolder = glob.glob(\"./images/train/*\")\n",
    "for i, value in enumerate(listfolder):\n",
    "    listfile = glob.glob(value + \"/*.*\")\n",
    "    for img in listfile:\n",
    "        print(img)\n",
    "        data.append(get128keypoint(img))\n",
    "        label.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "clf.fit(dataTrain, labelTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']}, {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.001, 0.0001]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'kernel': ['linear']},\n",
    "            {'C': [1, 10, 100, 1000],\n",
    "             'gamma': [0.001, 0.0001],\n",
    "             'kernel': ['rbf']}\n",
    "        ]\n",
    "clf = GridSearchCV(SVC(C=1, probability=True), param_grid, cv=5)\n",
    "clf.fit(dataTrain, labelTrain)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Enouvo_company/BuiMinhPhong/Test/56367274_1866853146752034_1279803514364624896_n.jpg\n",
      "./Enouvo_company/BuiMinhPhong/Test/Screenshot_6.png\n",
      "16\n",
      "./Enouvo_company/DangHy/Test/Screenshot_1.png\n",
      "6\n",
      "./Enouvo_company/DangHy/Test/Screenshot_8.png\n",
      "16\n",
      "./Enouvo_company/HoThiKhanhLy/Test/Screenshot_1.png\n",
      "./Enouvo_company/HoThiKhanhLy/Test/Screenshot_3.png\n",
      "./Enouvo_company/JasonNguyen/Test/Screenshot_1.png\n",
      "0\n",
      "./Enouvo_company/JasonNguyen/Test/Screenshot_3.png\n",
      "./Enouvo_company/MaiThiThuThuy/Test/Screenshot_1.png\n",
      "16\n",
      "./Enouvo_company/MaiThiThuThuy/Test/Screenshot_8.png\n",
      "./Enouvo_company/NguyenHuuTuongVi/Test/Screenshot_1.png\n",
      "./Enouvo_company/NguyenHuuTuongVi/Test/Screenshot_2.png\n",
      "./Enouvo_company/NguyenHuuTuongVi/Test/Screenshot_3.png\n",
      "9\n",
      "./Enouvo_company/NguyenLeBaoTram/Test/Screenshot_7.png\n",
      "./Enouvo_company/NguyenLeBaoTram/Test/Screenshot_8.png\n",
      "9\n",
      "wrong\n",
      "6\n",
      "14\n",
      "9\n",
      "./Enouvo_company/NguyenNhatNam/Test/Screenshot_2.png\n",
      "./Enouvo_company/NguyenNhatNam/Test/Screenshot_3.png\n",
      "./Enouvo_company/NguyenThiThanhPhuong/Test/Screenshot_1.png\n",
      "./Enouvo_company/NguyenThiThanhPhuong/Test/Screenshot_2.png\n",
      "./Enouvo_company/NguyenThiThanhPhuong/Test/Screenshot_4.png\n",
      "6\n",
      "6\n",
      "8\n",
      "4\n",
      "./Enouvo_company/NguyenTriCong/Test/Screenshot_1.png\n",
      "./Enouvo_company/NguyenTriCong/Test/Screenshot_2.png\n",
      "1\n",
      "./Enouvo_company/NguyenXuanHung/Test/Screenshot_1.png\n",
      "4\n",
      "./Enouvo_company/NguyenXuanHung/Test/Screenshot_3.png\n",
      "./Enouvo_company/PhamSiNguyen/Test/Screenshot_1.png\n",
      "./Enouvo_company/PhamSiNguyen/Test/Screenshot_10.png\n",
      "4\n",
      "16\n",
      "./Enouvo_company/PhamThiNgocAnh/Test/Screenshot_2.png\n",
      "./Enouvo_company/PhamThiNgocAnh/Test/Screenshot_3.png\n",
      "./Enouvo_company/TranHanhTrang/Test/Screenshot_1.png\n",
      "12\n",
      "7\n",
      "./Enouvo_company/TranTHiMyLinh/Test/Screenshot_1.png\n",
      "0\n",
      "14\n",
      "./Enouvo_company/TranThiThuHien/Test/Screenshot_1.png\n",
      "14\n",
      "0\n",
      "./Enouvo_company/TruongThiYNhi/Test/46503962_1239457629540607_5396997539843014656_o.jpg\n",
      "./Enouvo_company/TruongThiYNhi/Test/Screenshot_3.png\n",
      "./Enouvo_company/TruongThiYNhi/Test/Screenshot_8.png\n",
      "./Enouvo_company/VoThiThanhTuyen/Test/Screenshot_1.png\n",
      "./Enouvo_company/VoThiThanhTuyen/Test/Screenshot_2.png\n",
      "0\n",
      "./Enouvo_company/VoThiThanhTuyen/Test/Screenshot_4.png\n"
     ]
    }
   ],
   "source": [
    "result = 0\n",
    "for idx, testImg in enumerate(dataTest):\n",
    "    img = get128keypoint(testImg)\n",
    "    if img is not False:\n",
    "        rep = img.reshape(1, -1)\n",
    "        predictions = clf.predict_proba(rep).ravel()\n",
    "        maxI = np.argmax(predictions)\n",
    "        if (maxI == labelTest[idx] ):\n",
    "            result = result + 1\n",
    "            print(testImg)\n",
    "        else :\n",
    "            print(maxI)\n",
    "    else : \n",
    "        print(\"wrong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print(result)\n",
    "print(len(dataTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.06596053e-17 3.92894114e-11 6.83670456e-35 1.00000000e+00\n",
      " 1.32545410e-12 4.48815417e-70] 0.9999999999593854\n"
     ]
    }
   ],
   "source": [
    "rep = get128keypoint('./images/xp6.jpg').reshape(1, -1)\n",
    "predictions = clf.predict_proba(rep).ravel()\n",
    "maxI = np.argmax(predictions)\n",
    "confidence = predictions[maxI]\n",
    "print(predictions, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get128keypointTest(pathname):\n",
    "    img = cv2.imread(pathname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = cv2.resize(img, (96, 96), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    if img is not False:\n",
    "        img = img[...,::-1]\n",
    "        img = np.around(np.transpose(img, (0,1,2))/255.0, decimals=12)\n",
    "        x_train = np.array([img])\n",
    "        y1 = model.predict_on_batch(x_train)\n",
    "        return y1[0]\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0487835 ,  0.02638223, -0.07230595, -0.07985031,  0.0052608 ,\n",
       "        0.08356217, -0.01922345, -0.01764362,  0.02354503, -0.07758575,\n",
       "       -0.01393996,  0.07211049,  0.10336382, -0.114964  , -0.08214266,\n",
       "       -0.0149932 , -0.15426385, -0.09215006, -0.16866918,  0.2300697 ,\n",
       "        0.07824177, -0.02291875,  0.09083769,  0.05731176, -0.16006744,\n",
       "        0.08460534, -0.05663537, -0.17049293, -0.01825422,  0.03342596,\n",
       "       -0.05120825,  0.04528322, -0.01049708,  0.10250849, -0.02599949,\n",
       "        0.03421171,  0.0191655 ,  0.28396183, -0.08411465, -0.00988444,\n",
       "       -0.04047473, -0.06698567, -0.08416975,  0.04996787, -0.0839885 ,\n",
       "        0.00601189,  0.12507719,  0.06885215, -0.07777947,  0.21923834,\n",
       "       -0.04018158, -0.00929337, -0.06666382,  0.12204283,  0.20658225,\n",
       "       -0.08266607,  0.01025563,  0.04867583, -0.05833682, -0.17933074,\n",
       "       -0.04935848, -0.02176182,  0.20164338, -0.03364203,  0.00150317,\n",
       "       -0.14073004,  0.0474381 ,  0.0888806 , -0.00668177,  0.00590358,\n",
       "       -0.0110024 , -0.00417515, -0.02652256,  0.12690644,  0.06274395,\n",
       "       -0.02859057, -0.06849631,  0.0117471 ,  0.08291945,  0.1200335 ,\n",
       "        0.04087947,  0.04838305, -0.05015672, -0.03664966, -0.02473319,\n",
       "       -0.02164297,  0.04510098,  0.0965748 ,  0.12934162,  0.06657352,\n",
       "        0.08757091, -0.16250007,  0.00480604, -0.0002941 , -0.08770535,\n",
       "       -0.06988135,  0.01369381,  0.04797923,  0.05671182, -0.07730789,\n",
       "        0.04679263,  0.01636213, -0.08780938,  0.09526655, -0.10691074,\n",
       "        0.01964844, -0.14479505,  0.09728442,  0.02303883, -0.00743529,\n",
       "        0.0529459 ,  0.20606703, -0.11294926,  0.03763431,  0.00334844,\n",
       "        0.09956374, -0.04831345, -0.14228195, -0.02732162,  0.10290731,\n",
       "        0.0252519 ,  0.09285223,  0.12839368,  0.07265235, -0.0640756 ,\n",
       "        0.00296903,  0.04437032, -0.01974317], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get128keypointTest(\"./images/pp9.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
